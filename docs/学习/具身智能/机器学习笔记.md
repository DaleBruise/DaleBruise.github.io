# 机器学习笔记

---

此笔记记录了机器学习过程中的主要的知识点内容和理解。  

## 1.回归与逻辑回归

---

### 1.1 回归的定义与构建回归模型  

回归(regression)就是根据数据模式预测未来的数据走向。我们首先可以根据在图标中的样式观察两者是否有线性或者非线性关系，然后将模型适配至数据中，最后选择出最适配数据的模型。因此如何选择适当的模型是回归过程中的关键。相对书面一点，我们需要根据误差 $min\sum e$ 求回归系数 $\beta$ 。  

在python里面这一过程的迭代优化已经被封装起来，我们直接调用函数即可。  

### 1.2 R-squared  

实际的数据预测中，真实值、预测值和误差之间的关系如下：  

$$
Y(真实值) = Y(预测值) + E(误差)
$$

因此在 $y$ 处的总方差=回归模型的可解释方差+未解释方差

$$
SST = SSR + SSE
$$

对于一个好模型来讲 $SST$ 越接近1就是越接近真实值，由此可以定义一个评判一个模型好坏的标准$R-sqaured$：  

$$
R-squared = \frac{SSR}{SST}
$$

在工业界中 $R-sqaured$ 的最小值为0.8。  

### 1.3 多元回归与回归中的多重共线性  

在进行数据分析时，可能会有多个不同的数据都会对预测值有影响。比起使用单独自变量预测数据，我们可以使用多个自变量进行回归，这就是多元回归。  

简单的线性回归方程：
$$
y = \beta_{0} + \beta_{1}x
$$  

使用多个变量的线性多元回归方程: 

$$
y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_2{2}...... + \beta_{k}x_{k}
$$

使用多元回归往往会带给我们更高的R-sqaured值，也就是意味着更正确的模型。但是其几个自变量也会存在一些问题，比如这些多元自变量中会存在线性相关的向量组。这样的关系（依赖关系），我们可以称之为回归中的多重共线性。  

我们为什么需要关注多重共线性？这是因为多重共线性会对模型带来信任挑战，即模型中的部分相关系数是不可靠的，这是为什么呢？  

假如三个自变量 $x_1, x_2, x_3$ 中， $x_1, x_3$ 有着 $x_1 = 2x_3$ 的线性关系，那么对于一个模型来讲，预测的结果并不存在唯一的解。也就是脱离了数学中方程的定义——一组自变量只对应一个因变量，如果这个定义被打破，那么就不存唯一的映射关系，我们也无法准确预测这个结果。  
若几个自变量之间存在一些线性关系，那么我们并不需要这么多组的数据也可以正确地预测，也就是对R-squared值不会有太多的影响。简而言之，我们要去发现回归中的多重共线性，并且除掉它。  

具体方法简而言之，我们可以求出自变量的个数个 $VIF$ 值（方差膨胀因子）。当 $VIF$ 值大于5时，就说明这个变量存在多重共线性。计算公式为：  

$$ 
VIF = \frac{1}{1 - R_{i}^2}
$$

其中 $R_i$ 是对应变量 $x_i$ 的R-sqaured值。 

### 1.4 回归中各变量的影响力  

我们计算了多重性，已经排除了非影响回归的因素。但这还不够，如果是一个变量，那么这个变量对回归的影响力是百分之百；但如果是多个变量，每一个变量对回归的影响不一定相同，所以我们要求出每一个变量对于回归的影响是多少，这是构建回归模型的必要步骤。  

使用t-test和P-value就可以检测出各变量对回归的影响程度。若P-value这个值大于0.05，说明该变量对回归的影响很小，计算方法已经集成到python的summary方法中，下面简单介绍一下：  

- 原假设 $H_0$ ：变量 $x_p$ 是没有影响力的变量( $\beta_0 = 0$ )
- 备择假设 $H_1$ ：变量 $x_p$ 是有影响力的变量( $\beta_0 \neq 0$ )
- 测试统计值：$t=\frac{\beta_p}{s(\beta_p)}$ 
- 如果 $t>t(/frac{\alpha}{2};n-k-1)$ 或者 $t<-t(/frac{\alpha}{2};n-k-1)$  并且设置 $\alpha$ 为5%，则拒绝原假设。

### 1.5 构建多元回归模型的步骤(总结)  

略

### 1.6 逻辑回归模型  

逻辑回归模型不同于线性回归模型，逻辑回归更倾向于模拟0或者1的情况，或者-1，0或者1的情况。是一种逻辑判断。但是数学中，没有绝对的逻辑回归连续函数，想要用连续函数来预测的话，我们可以使用指数函数来进行建模：  

$$
y=\frac{e^x}{1+e^x}
$$

对于逻辑回归模型中也有线性系数要求解：  

$$
y=\frac{e^{\beta_{0}+\beta_{1}x}}{1+e^{\beta_{0}+\beta_{1}x}}
$$

其中， $\beta_0,\beta_1$ 就是我们要求解的线性系数。 

### 1.7 逻辑回归线的准确率  

逻辑回归的计算方法与线性回归中的方法不太相同，但是思路上是大同小异的。我们根据预测的模型来根据原数据进行预测，然后将预测值与真实值进行比较。由于只有0和1的情况，所以只会存在一些以下四种情况： $[0,1], [0,0], [1,1], [1,0]$ 。  

这种矩阵叫做混淆矩阵(confusion matrix)，同时也可以根据此矩阵计算出一个准确率比值：  

$$
准确率 = \frac{正确分类的个数}{总个数}
$$

$$
准确率 = \frac{cm[0,0]+cm[1,1]}{cm[0,0]+cm[1,0]+cm[0,1]+cm[1,1]}
$$

### 1.8 多元逻辑回归的多重共线性和个体影响力  

同多元线性回归模型，此处略。  


## 2.决策树

---

### 2.1 什么是决策树？决策树的分类准则是什么？  

决策树类似一种逻辑分类，其基础是一种二叉树。每一层都根据一个元素分成两类，然后下一层在上一层的基础上就会再分，预测时根据这层分类标准进行遍历（先序遍历）。

### 2.2 决策树算法  

略

### 2.3 过拟合问题

略


## 3.模型选择和交叉验证  

---

首先，我们要谨慎地选择数据集，并且对原始的数据集要有一定的筛选和处理。然后我们就可以进型建模，建模过后不能过早地看到建模的结果很好就部署，而是要对模型有一定的选择过程。就是因为你选择的模型并不一定是最佳答案，或者可能会有更正确的答案，所以我们要对模型进行流程上的验证。  

同时，部署模型过后，也并不是什么都不做，因为总会有新的数据到来。新的数据会不会不适应这个“过去”的模型？也会是一个问题。所以我们要进行进一步的验证，也就是既要满足过去的数据集，也要满足新的数据集，让模型更加健壮和长时间正确。  

### 3.1 构建模型的步骤

构建模型的生命周期分为以下五个步骤：  
1. **定义模型并完成目标。**
	首先是要定义我们的任务是什么？完整的目标是什么？然后去分析数据的输入和输出的特征。  
2. **探索、验证及准备数据。**  
	- 对数据集的row和column进行分辨，查看有没有一些明显的缺失等问题
	- 分析每一个单row或者column，查看有没有奇异值
	- 根据上述的分析，筛选出干净有用的数据开始分析
	- 对一些文本数据转换成数字睡觉  
3. **构建模型。**  
	- 选择合适的模型
	- 查看数据集的类型是分类数据还是回归数据
	- 选择相同类型的三个及以上的模型进行尝试
	- 尝试不同的特征来训练模型  
4. **验证模型。**  
	- 使用R-sqaured或者准确率进行必要的模型验证
	- 在训练数据集和预测数据集上进行验证
	- 找出可能使模型失败的数据集进行验证  
5. **部署模型。**  
	……  

### 3.2 模型验证指标：回归  

回归模型中我们基本上会围绕标准差和标准房差进行验证，除了R-squared之外，还包含：**MAD**，**MAPE**，**RMSE**。  

1. 平均绝对离差**MAD**
	该指标的公式如下所示：  
	$$
	MAD = \sum_{i=1}^n {\frac{\left\vert y_i - \hat{y_i} \right\vert}{n}}
	$$
	公式中可以看出，**MAD**其实就是标准差的均值，当**MAD**越小时，就说明数据的偏差越小。但是**MAD**的值没有很好的范围标准，当数据偏大时，**MAD**的值也会很大，但是并不一定代表数据会偏差很多。
2. 平均绝对离差百分比**MAPE**
	该指标的公式如下所示：
	$$
	MAPE = \frac{100}{n}\sum_{i=1}^n {\frac{\left\vert y_i - \hat{y_i} \right\vert}{y_i}}
	$$
	**MAPE**从公式中，可以发现本质上是**MAD**的百分比形式。在使用这个标准的时候，就可以不太关注数据的规模。
3. 均方根误差**RMSE**
	该指标的公式：  
	$$
	RMSE = \sqrt{\sum_{i=1}^n {\frac{(y_i - \hat{y_i})^2}{n}}}
	$$
	该指标越小，说明数据的偏差度就越小。  


### 3.3 模型验证指标：分类  

对于逻辑回归模型，也就是分类任务时，我们需要使用混淆矩阵和准确率来对模型进行验证。    

但是我们可能会遇到一种情况：准确率非常高的时候，也就是接近99%。那么我们预测正确数据，也就是 $cm[0,0]$ 的概率会很高，但是由于正确的错误数据相对太少，所以我们对整的错误数据，也就是 $cm[1,1]$ 的概率会很低，这是数据量不够导致的。为了判断这种情况是否存在，我们需要使用两种指标：**灵敏度**和**特异度**来进行判断。  

1. **灵敏度**
	灵敏度是第一个分类的准确率，按照惯例就是 $cm[0,0]$ 的比例，我们也称正例类的比例：  
	$$
	\begin{aligned}
	灵敏度 & = \frac{cm[0,0]}{cm[0,0] + cm[0,1]}\\
	& = \frac{真正例(TP)}{真正例(TP) + 假反例(FN)}\\
	\end{aligned}
	$$
2. **特异度**
	反之，特异度是第二个分类的准确率，按照惯例是 $cm[1,1]$ 的比例，我们也称正反例的比例：  
	$$
	\begin{aligned}
	特异度 & = \frac{cm[1,1]}{cm[1,1] + cm[1,0]}\\
	& = \frac{真反例(TN)}{真反例(TN) + 假正例(FP)}\\
	\end{aligned}
	$$  

一般这两种指标，不是只看其中一个。一般情况下，我们倾向于较高的灵敏度，较低的特异度，但是特异度不能像上述情况一样，过于低。所以我们需要另外的指标来使模型的灵敏度和特异度达到较为平衡的水平，也就是**ROC**和**AUC**。  

1. **ROC**受试者工作特征
	ROC是一种曲线，横坐标是特异度，纵坐标是灵敏度。二者往往会呈现一种对数函数曲线形式。我们通常会选择拐点的位置作为最终模型的灵敏度和特异度。
2. **AUC**
	AUC是ROC曲线的对角线。ROC曲线离AUC线越远，就代表模型越好。  

另外还有一种指标叫做**F1 Score**，F1 Score是灵敏度和特异度的一种拓展。

### 3.4 权衡偏差与方差  

模型也会有过拟合问题和欠拟合问题，拟合过度会导致未来数据的不精确，拟合欠缺会导致训练数据和未来数据与模型不匹配。因此一个好的模型不仅不能拟合过度，也要让拟合不那么欠缺。衡量这两个问题的指标为**方差**和**偏差**。  

模型中的广义误差可以分为三个部分，**不可约误差**，**偏差**和**方差**。  

**不可约误差**就是数据中总会存在一些无法减少的固有误差，就是无论你拟合出多么好的模型，都会有误差，不可能所有的数据都是100%0误差。**偏差**是由欠拟合造成的，**方差**是由过拟合造成的。总方差的公式如下：  

$$
总方差 = 不可约误差 + 偏差^2 + 方差
$$

**偏差**和**方差**往往是反方向增长的，当**偏差**减少时，可能**方差**会很大；**方差**很小时，**偏差**会很大。所以我们找到一个平衡点。  

### 3.5 交叉验证  

交叉验证是指在训练数据上构建模型，并且在测试数据上验证模型。测试数据和训练模型都是数据集中分散提取的两部分数据。 

目前有一种经典的**K-折交叉验证**，通常K是一个代表比例的一个数字。若K=10，则代表将整体数据集分成十份，即每一份占整体数据集的10%，这是第一步。  

其次，我们需要构建K个模型。首先我们对数据集的每一个字集编序号，我们可以将第一个字集作为验证子集，然后剩余的字集作为训练子集。后面的模型都是如此，第二个模型就是将第二个子集作为验证子集，剩余子集作为训练子集。重复这个步骤，我们就可以得到K个模型。  

最后，我们要将这几个模型都计算准确率，用平均准确率作为整体一次的建模过程的准确率。我们每一次调整参数都要看这个准确率。所以这个方法的时间复杂度和操作复杂度都很高，我们可以使用别的方法——**训练集-验证集-留出交叉验证方法**。  

差别在于，留出数据集是不用于前面的交叉验证过程和调整过程，而是用于最后的模型测试。所以在一定的方面能够平衡**K-折交叉验证**的高时间复杂度的问题。  

## 4. 聚类分析  

---

### 4.1 





 
